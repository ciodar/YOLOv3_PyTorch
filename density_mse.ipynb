{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime  # <1>\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "import torch\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1792, 1024, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=1024)\n",
    "        self.conv2 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=512)\n",
    "        self.fc1 = nn.Linear(512 * 4 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1_batchnorm(self.conv1(x))), 2)\n",
    "        out = torch.tanh(self.conv2_batchnorm(self.conv2(out)))\n",
    "        out = out.view(-1, 512 * 4 * 5)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = torch.tanh(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, valid_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.float().to(device=device).unsqueeze(1)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        train_losses.append(loss_train/len(train_loader))\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "        test(model,valid_loader,device)\n",
    "\n",
    "def evaluate(model,train_loader,valid_loader,device):\n",
    "    print(f\"Validating on device {device}.\")\n",
    "\n",
    "    model.to(device=device)  # <2>\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    predictions = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", valid_loader)]:\n",
    "        y_true = torch.tensor([], dtype=torch.float, device=device)\n",
    "        all_outputs = torch.tensor([], device=device)\n",
    "        with torch.no_grad():\n",
    "            for data, labels in loader:\n",
    "                data = data.to(device=device)\n",
    "                labels = labels.to(device=device).unsqueeze(1).float()\n",
    "                y_true = torch.cat((y_true, labels), 0)\n",
    "                outputs = model(data)\n",
    "                all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        all_outputs = all_outputs.cpu().numpy()\n",
    "        predictions[name]=(y_true,all_outputs)\n",
    "    return predictions\n",
    "\n",
    "def test(model,valid_loader,device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,labels in valid_loader:\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device).unsqueeze(1).float()\n",
    "            outputs = model(data)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            # correct += torch.round(outputs).eq(labels).sum().item()\n",
    "\n",
    "    valid_loss = running_loss / len(valid_loader)\n",
    "    # accu = 100. * correct / total\n",
    "\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "train_path = pl.Path('D:/results/Feature extraction/flir dataset/fm_kaist_density_10_8/kaist_results_train.pt')\n",
    "valid_path = pl.Path('D:/results/Feature extraction/flir dataset/fm_kaist_density_10_8/kaist_results_valid.pt')\n",
    "\n",
    "dateTimeObj = datetime.now()\n",
    "\n",
    "outdir = pl.Path.joinpath(train_path.parent,str(dateTimeObj.year)+ '_' + \\\n",
    "                          str(dateTimeObj.month) + '_' + \\\n",
    "                          str(dateTimeObj.day) + '_' + str(dateTimeObj.hour) + '_' + \\\n",
    "                          str(dateTimeObj.minute) + '_' + str(dateTimeObj.second))\n",
    "\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "# train loader\n",
    "train_label_path = pl.Path.joinpath(train_path.parent, train_path.stem + '_labels' + train_path.suffix)\n",
    "t1 = torch.load(train_path)\n",
    "t1 = t1.reshape(8862, 1792, 8, 10)\n",
    "t2 = torch.load(train_label_path).reshape(8862)\n",
    "print(\"Loaded train features from {},labels from {}\".format(str(train_path),str(train_label_path)))\n",
    "trainset = list(zip(t1, t2))\n",
    "train_loader = D.DataLoader(trainset, batch_size=64,\n",
    "                            shuffle=True)\n",
    "\n",
    "# test loader\n",
    "valid_label_path = pl.Path.joinpath(valid_path.parent, valid_path.stem + '_labels' + valid_path.suffix)\n",
    "v1 = torch.load(valid_path)\n",
    "v1 = v1.reshape(1366, 1792, 8, 10)\n",
    "v2 = torch.load(valid_label_path).reshape(1366)\n",
    "print(f\"Loaded valid features from {str(valid_path)},labels from {str(valid_label_path)}\")\n",
    "valset = list(zip(v1, v2))\n",
    "valid_loader = torch.utils.data.DataLoader(valset, batch_size=64,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    "    valid_loader=valid_loader\n",
    ")\n",
    "\n",
    "predictions = evaluate(model,train_loader,valid_loader,device)\n",
    "\n",
    "train_predict = np.array(predictions['train'])\n",
    "train_predict = train_predict.reshape(2,train_predict.shape[1]).transpose()\n",
    "eval_predict = np.array(predictions['val'])\n",
    "eval_predict = eval_predict.reshape(2,eval_predict.shape[1]).transpose()\n",
    "\n",
    "print(f\"Train MSE: {mean_squared_error(train_predict[:,0],train_predict[:,1]):.2f}\")\n",
    "print(f\"Valid MSE: {mean_squared_error(eval_predict[:,0],eval_predict[:,1]):.2f}\")\n",
    "\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), pl.Path.joinpath(outdir, 'trained_model.pt'))\n",
    "\n",
    "np.save(pl.Path.joinpath(outdir,'mse_train_arr'),train_predict)\n",
    "np.save(pl.Path.joinpath(outdir,'mse_valid_arr'),eval_predict)\n",
    "\n",
    "mse_train_by_num= [mean_squared_error(train_predict[train_predict[:, 0] == i][:, 0] \\\n",
    "                                            ,train_predict[train_predict[:, 0] == i][:, 1]) \\\n",
    "                          for i in np.unique(train_predict[:,0])]\n",
    "\n",
    "mse_val_by_num = [mean_squared_error(eval_predict[eval_predict[:, 0] == i][:, 0] \\\n",
    "                                        , eval_predict[eval_predict[:, 0] == i][:, 1]) \\\n",
    "                    for i in np.unique(eval_predict[:, 0])]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('losses')\n",
    "plt.legend(['Train', 'Valid'])\n",
    "plt.title('Train vs Valid Losses')\n",
    "plt.savefig(pl.Path.joinpath(outdir,'train_loss.png'))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(mse_train_by_num)\n",
    "plt.plot(mse_val_by_num)\n",
    "plt.grid()\n",
    "plt.xlabel('person count')\n",
    "plt.ylabel('mse')\n",
    "plt.legend(['Train', 'Valid'])\n",
    "plt.title('Train vs Valid MSE by number of people')\n",
    "plt.savefig(pl.Path.joinpath(outdir,'train_mse_by_people.png'))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tesi_pytorch",
   "language": "python",
   "display_name": "Python (tesi_pytorch)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}